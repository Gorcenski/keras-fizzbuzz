{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import types\n",
    "import tempfile\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_accuracy_keras(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis=1), K.argmax(y_pred, axis=1)))\n",
    "\n",
    "def extract_features(i):\n",
    "    return [i % 2, i % 3, i % 5, i % 7, i % 11, i % 13]\n",
    "#     return [i % 2, i % 5, i % 7, i % 11, i % 13, i % 17, i % 19, i % 23, i % 29, i % 31]\n",
    "#     return [i % (k + 1) for k in range(15)]\n",
    "\n",
    "def fizzbuzz(i):\n",
    "    if i % 15 == 0:\n",
    "        return 3\n",
    "    if i % 5 == 0:\n",
    "        return 2\n",
    "    if i % 3 == 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the training data and the labels\n",
    "data = np.array([extract_features(i) for i in range(500,5500)])\n",
    "labels = np.array([fizzbuzz(i) for i in range(500,5500)])\n",
    "dim = np.shape(data)[1]\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keras_picklable()\n",
    "\n",
    "# specify the network\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_dim=dim))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 3.0850 - acc: 0.2246\n",
      "Epoch 2/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.7886 - acc: 0.3274\n",
      "Epoch 3/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.3914 - acc: 0.3864\n",
      "Epoch 4/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.1999 - acc: 0.4384\n",
      "Epoch 5/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.0729 - acc: 0.5158\n",
      "Epoch 6/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 0.9499 - acc: 0.5784\n",
      "Epoch 7/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 0.8242 - acc: 0.6202\n",
      "Epoch 8/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 0.7077 - acc: 0.6958\n",
      "Epoch 9/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 0.5936 - acc: 0.7988\n",
      "Epoch 10/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 0.4872 - acc: 0.8960\n",
      "Epoch 11/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 0.3896 - acc: 0.9478\n",
      "Epoch 12/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 0.3079 - acc: 0.9752\n",
      "Epoch 13/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 0.2392 - acc: 0.9900\n",
      "Epoch 14/200\n",
      "5000/5000 [==============================] - 0s 25us/step - loss: 0.1813 - acc: 0.9970\n",
      "Epoch 15/200\n",
      "5000/5000 [==============================] - 0s 20us/step - loss: 0.1322 - acc: 0.9994\n",
      "Epoch 16/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 0.0946 - acc: 1.0000\n",
      "Epoch 17/200\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 18/200\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 19/200\n",
      "5000/5000 [==============================] - 0s 25us/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 20/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 21/200\n",
      "5000/5000 [==============================] - 0s 20us/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 22/200\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 23/200\n",
      "5000/5000 [==============================] - 0s 29us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 24/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 25/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 26/200\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 27/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 28/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 6.7374e-04 - acc: 1.0000\n",
      "Epoch 29/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 4.0546e-04 - acc: 1.0000\n",
      "Epoch 30/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 2.3746e-04 - acc: 1.0000\n",
      "Epoch 31/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.3467e-04 - acc: 1.0000\n",
      "Epoch 32/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 7.6213e-05 - acc: 1.0000\n",
      "Epoch 33/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 4.1909e-05 - acc: 1.0000\n",
      "Epoch 34/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 2.3261e-05 - acc: 1.0000\n",
      "Epoch 35/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2431e-05 - acc: 1.0000\n",
      "Epoch 36/200\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: 6.8733e-06 - acc: 1.0000\n",
      "Epoch 37/200\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: 3.8370e-06 - acc: 1.0000\n",
      "Epoch 38/200\n",
      "5000/5000 [==============================] - 0s 20us/step - loss: 2.1217e-06 - acc: 1.0000\n",
      "Epoch 39/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2354e-06 - acc: 1.0000\n",
      "Epoch 40/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 7.3609e-07 - acc: 1.0000\n",
      "Epoch 41/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 4.8582e-07 - acc: 1.0000\n",
      "Epoch 42/200\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: 3.3939e-07 - acc: 1.0000\n",
      "Epoch 43/200\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: 2.5661e-07 - acc: 1.0000\n",
      "Epoch 44/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 2.1174e-07 - acc: 1.0000\n",
      "Epoch 45/200\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: 1.8507e-07 - acc: 1.0000\n",
      "Epoch 46/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.6692e-07 - acc: 1.0000\n",
      "Epoch 47/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.5523e-07 - acc: 1.0000\n",
      "Epoch 48/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.4763e-07 - acc: 1.0000\n",
      "Epoch 49/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.4230e-07 - acc: 1.0000\n",
      "Epoch 50/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.3837e-07 - acc: 1.0000\n",
      "Epoch 51/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.3522e-07 - acc: 1.0000\n",
      "Epoch 52/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.3303e-07 - acc: 1.0000\n",
      "Epoch 53/200\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: 1.3132e-07 - acc: 1.0000\n",
      "Epoch 54/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2994e-07 - acc: 1.0000\n",
      "Epoch 55/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2859e-07 - acc: 1.0000\n",
      "Epoch 56/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2782e-07 - acc: 1.0000\n",
      "Epoch 57/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2703e-07 - acc: 1.0000\n",
      "Epoch 58/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2624e-07 - acc: 1.0000\n",
      "Epoch 59/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2567e-07 - acc: 1.0000\n",
      "Epoch 60/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2517e-07 - acc: 1.0000\n",
      "Epoch 61/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2473e-07 - acc: 1.0000\n",
      "Epoch 62/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2434e-07 - acc: 1.0000\n",
      "Epoch 63/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.2398e-07 - acc: 1.0000\n",
      "Epoch 64/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2372e-07 - acc: 1.0000\n",
      "Epoch 65/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2337e-07 - acc: 1.0000\n",
      "Epoch 66/200\n",
      "5000/5000 [==============================] - 0s 22us/step - loss: 1.2324e-07 - acc: 1.0000\n",
      "Epoch 67/200\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 1.2300e-07 - acc: 1.0000\n",
      "Epoch 68/200\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: 1.2280e-07 - acc: 1.0000\n",
      "Epoch 69/200\n",
      "5000/5000 [==============================] - 0s 22us/step - loss: 1.2257e-07 - acc: 1.0000\n",
      "Epoch 70/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2244e-07 - acc: 1.0000\n",
      "Epoch 71/200\n",
      "5000/5000 [==============================] - 0s 21us/step - loss: 1.2228e-07 - acc: 1.0000\n",
      "Epoch 72/200\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: 1.2214e-07 - acc: 1.0000\n",
      "Epoch 73/200\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 1.2197e-07 - acc: 1.0000\n",
      "Epoch 74/200\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: 1.2190e-07 - acc: 1.0000\n",
      "Epoch 75/200\n",
      "5000/5000 [==============================] - 0s 9us/step - loss: 1.2180e-07 - acc: 1.0000\n",
      "Epoch 76/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2167e-07 - acc: 1.0000\n",
      "Epoch 77/200\n",
      "5000/5000 [==============================] - 0s 22us/step - loss: 1.2158e-07 - acc: 1.0000\n",
      "Epoch 78/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.2150e-07 - acc: 1.0000\n",
      "Epoch 79/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.2137e-07 - acc: 1.0000\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2133e-07 - acc: 1.0000\n",
      "Epoch 81/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2125e-07 - acc: 1.0000\n",
      "Epoch 82/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2121e-07 - acc: 1.0000\n",
      "Epoch 83/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2115e-07 - acc: 1.0000\n",
      "Epoch 84/200\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 1.2110e-07 - acc: 1.0000\n",
      "Epoch 85/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2103e-07 - acc: 1.0000\n",
      "Epoch 86/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2094e-07 - acc: 1.0000\n",
      "Epoch 87/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2091e-07 - acc: 1.0000\n",
      "Epoch 88/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2088e-07 - acc: 1.0000\n",
      "Epoch 89/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2083e-07 - acc: 1.0000\n",
      "Epoch 90/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2076e-07 - acc: 1.0000\n",
      "Epoch 91/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2071e-07 - acc: 1.0000\n",
      "Epoch 92/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2069e-07 - acc: 1.0000\n",
      "Epoch 93/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2066e-07 - acc: 1.0000\n",
      "Epoch 94/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2059e-07 - acc: 1.0000\n",
      "Epoch 95/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2054e-07 - acc: 1.0000\n",
      "Epoch 96/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2052e-07 - acc: 1.0000\n",
      "Epoch 97/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2051e-07 - acc: 1.0000\n",
      "Epoch 98/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2045e-07 - acc: 1.0000\n",
      "Epoch 99/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2043e-07 - acc: 1.0000\n",
      "Epoch 100/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2040e-07 - acc: 1.0000\n",
      "Epoch 101/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2037e-07 - acc: 1.0000\n",
      "Epoch 102/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2034e-07 - acc: 1.0000\n",
      "Epoch 103/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2034e-07 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.2031e-07 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2027e-07 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2027e-07 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2027e-07 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2023e-07 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2022e-07 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2022e-07 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2022e-07 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.2017e-07 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2015e-07 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2014e-07 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2013e-07 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2010e-07 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2009e-07 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2009e-07 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2009e-07 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2009e-07 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2007e-07 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.2006e-07 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.2004e-07 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2002e-07 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.2000e-07 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1998e-07 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1996e-07 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1994e-07 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1994e-07 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1992e-07 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1992e-07 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1992e-07 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1992e-07 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1992e-07 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1990e-07 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1990e-07 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1990e-07 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1988e-07 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1988e-07 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1986e-07 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1986e-07 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1985e-07 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1984e-07 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1984e-07 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1982e-07 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1981e-07 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1981e-07 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.1978e-07 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 19us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1973e-07 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1972e-07 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1972e-07 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1971e-07 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1971e-07 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1970e-07 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1967e-07 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1969e-07 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1966e-07 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1966e-07 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1965e-07 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1965e-07 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1965e-07 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1965e-07 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1964e-07 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1961e-07 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1961e-07 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1961e-07 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1961e-07 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "5000/5000 [==============================] - 0s 17us/step - loss: 1.1959e-07 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 1.1957e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5618373c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, iterating on the data in batches of 64 samples\n",
    "model.fit(data, one_hot_labels, epochs=200, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 18us/step\n",
      "[1.1956691741943358e-07, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(data, one_hot_labels, batch_size=64)\n",
    "print(score)\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"mymodel.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_filename, 'rb') as file:\n",
    "    PICKLE_MODEL = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_built'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-02911a316ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-02911a316ab8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-02911a316ab8>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPICKLE_MODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'fizz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    642\u001b[0m                                batch_size=None):\n\u001b[1;32m    643\u001b[0m         \u001b[0mall_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m             \u001b[0;31m# We need to use `x` to set the model inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# We type-check that `x` and `y` are either single arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mbuilt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_built'"
     ]
    }
   ],
   "source": [
    "def classify(i):\n",
    "    prediction = PICKLE_MODEL.predict(np.array([extract_features(i)]))\n",
    "    result = np.argmax(prediction)\n",
    "    if result == 1:\n",
    "        return 'fizz'\n",
    "    if result == 2:\n",
    "        return 'buzz'\n",
    "    if result == 3:\n",
    "        return 'fizzbuzz'\n",
    "    return str(i)\n",
    "\n",
    "[classify(i) for i in range(1, 100 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('myfile.pkl', 'wb')\n",
    "pickle.dump(model, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
